---
title: "My Final Project Template"
author: Yue Ma
subtitle: Subtitle here if desired
---

# Introduction

[~ 200 words]

Time series data is of tremendous importance in the field of environmental sustainability. Exploring this kind of data helps us understand the pattern of ecosystems, which allows us to detect the abnormal changes in time and help the relative department to make decisions. In this study, I will compare the performances of two state-of-the-art time series classification (TSC) models, fully convectional neural network (FCN) and deep Residual Network (ResNet).

# Materials and methods

[~ 200 words]

Narrative: Clear narrative description of the data sources and methods. Includes data from at least two sources that were integrated / merged in R.

Code: The code associated with the project is well organized and easy to follow. Demonstrates mastery of R graphics and functions.

Data: The underlying data are publicly accessible via the web and downloaded/accessed within the Rmd script. If you want to use your own data, you must make it available on a website (e.g. Figshare) so that others are able to re-run your code.

You can do bullets like this:

* The first most important thing
* The second most important thing
* The third most important thing

You can do numbers like this:

1. The first most important thing
2. The second most important thing
3. The third most important thing

See [http://rmarkdown.rstudio.com/](http://rmarkdown.rstudio.com/) for all the amazing things you can do.


Here's my first code chunk.
```{r}
1+2
```

Load any required packages in a code chunk (you may need to install some packages):

```{r, message=F, warning=F}
library(tidyverse)
library(leaflet)
library(kableExtra)
knitr::opts_chunk$set(cache=TRUE)  # cache the results for quick compiling
```

## Download and clean all required data
Here, I load all the NDVI data and compact them as one three-dimensional array. I firstly go through the data to check if there is any N.A or infinity values in the array. If there are infinity values, replace them with N.A values. 

```{r}
n=20
data=data.frame(x=runif(n,-180,180),
                y=runif(n,-60,60),
                size = runif(n, 5, 20),
                category = factor(
                  sample(letters[1:5], n, replace = TRUE)
                  ),
                value = rnorm(n))
```
After the replace step, I normalize the NDVI value to the value range [-1,1].
```{r, results='asis'}
data %>% 
  slice(1:10) %>% #show only 1:n rows
  kable(digits=2,align="c")%>% #make table and round to two digits
  kable_styling(bootstrap_options = 
                  c("striped", "hover", "condensed", "responsive")) #apply other formatting
```

Then I load the environmental variables and check if there is any N.A or infinity data as well. If there are infinity values, replace them with N.A values. Then normalize the environmental variables to the value range (0,1]. 

Replace all the N.A values with 0 and compact them as one array.

## build the training and testing dataset

Load the land cover classification dataset and compare the value of each pixel from year to year. Save the location of pixels which don't change during the study period and build a mask based on these pixels.

Use the mask to filter out the pixels in the compacted time series dataset. Then filter out all the pixels who have 0 in their environmental variables.

Convert the 3-dimensional dataset to 2-dimensional dataset. After this, add labels to the 2-dimensional dataset. Then use continuous numbers to replace the original label numbers.

Randomly split the dataset (75%-25%) as training dataset and testing dataset.

## build and train the model
Build the FCN model and train it with the training dataset.

Build the ResNet model and train it with the training dataset.

Test the models with testing dataset, and evaluate them.


# Results

[~200 words]

Tables and figures (maps and other graphics) are carefully planned to convey the results of your analysis. Intense exploration and evidence of many trials and failures. The author looked at the data in many different ways before coming to the final presentation of the data.

Show tables, plots, etc. and describe them.

```{r, fig.width=6, fig.height=3, fig.cap="Map of completely random data"}
m <- leaflet(data) %>% 
  addTiles() %>% 
  addCircleMarkers(~x, ~y, radius = ~size,color = ~as.factor(category)) %>% 
  addPopups(~x[2], ~y[2], "Random popup")
m  # a map with the default OSM tile layer
```


```{r}
data %>% 
  ggplot(aes(x=x,y=y,col=category))+
  geom_point()
```

# Conclusions

[~200 words]

Clear summary adequately describing the results and putting them in context. Discussion of further questions and ways to continue investigation.

# References

All sources are cited in a consistent manner
